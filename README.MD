# Техническое задание на позицию: Junior Python разработчик

## Задание:
Сбор данных с сайта [https://quotes.toscrape.com/](https://quotes.toscrape.com/)

## Результаты:
1. JSON файл с собранными данными.
2. MD файл с анализом задачи, включающий:
   - Что было сделано
   - Откуда были получены данные
   - Как осуществлялся сбор
   - Почему был выбран тот или иной метод/инструмент, а не другой
3. Ссылка на репозиторий с кодом на GitHub.

## Анализ задачи

### Что было сделано
Был написан скрипт на Python для сбора данных с сайта [https://quotes.toscrape.com/](https://quotes.toscrape.com/). Скрипт собирает цитаты, авторов и теги, связанные с каждой цитатой. Собранные данные сохраняются в JSON файл.

### Откуда были получены данные
Данные были получены с сайта [https://quotes.toscrape.com/](https://quotes.toscrape.com/). Сайт предоставляет цитаты, авторов и теги, которые можно собрать с помощью веб-скрапинга.

### Как осуществлялся сбор
Для сбора данных был использован библиотека `requests` для отправки HTTP-запросов и библиотека `BeautifulSoup` для парсинга HTML-контента. Скрипт проходит по всем страницам сайта, собирает необходимые данные и сохраняет их в JSON файл.

### Почему был выбран тот или иной метод/инструмент, а не другой
- **requests**: Библиотека `requests` была выбрана для отправки HTTP-запросов из-за её простоты и удобства использования. Она позволяет легко отправлять запросы и получать ответы.
- **BeautifulSoup**: Библиотека `BeautifulSoup` была выбрана для парсинга HTML-контента из-за её мощных возможностей для работы с HTML и XML. Она позволяет легко извлекать данные из HTML-документов.
- **JSON**: Формат JSON был выбран для сохранения данных из-за его простоты и универсальности. JSON легко читается и записывается, что делает его удобным для хранения и передачи данных.
